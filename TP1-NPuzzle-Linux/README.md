# TP1 â€” Recherche dâ€™Ã©tats : Taquin (N-Puzzle)

UniversitÃ© Grenoble Alpes â€” M1 Informatique
UE : Planification automatique et techniques d'intelligence artificielle
**Nom : BENAOUDIA Ilian**

---

## ğŸŒŸ Objectif du TP

ImplÃ©menter et comparer plusieurs algorithmes de recherche dans un espace d'Ã©tats, appliquÃ©s au **taquin (n-puzzle)** :

* **BFS** (Breadth First Search)
* **DFS** (Depth First Search)
* **A\*** (A-star) avec heuristique de Manhattan

Comparer leurs performances sur des puzzles de difficultÃ© croissante.

---

## ğŸ“‚ Structure du projet

```
TP1-NPuzzle/
â”œâ”€â”€ npuzzle/               # Code source du taquin
â”œâ”€â”€ puzzles/               # Puzzles gÃ©nÃ©rÃ©s automatiquement
â”œâ”€â”€ results/               # CSV + graphe de performance
â”œâ”€â”€ benchmark.py           # Script pour mesurer les performances (compatible VM PATIA)
â”œâ”€â”€ plot_results.py        # Script pour tracer le graphe (compatible VM PATIA)
â”œâ”€â”€ solve_npuzzle.py       # RÃ©solution du taquin (Python 3.7+)
â”œâ”€â”€ generate_npuzzle.py    # GÃ©nÃ©ration de puzzles alÃ©atoires (Python 3.7+)
â”œâ”€â”€ README.md              # PrÃ©sent fichier
```

---

## ğŸš€ Utilisation (compatible VM PATIA)

### 1. GÃ©nÃ©rer les puzzles

La gÃ©nÃ©ration est automatiquement intÃ©grÃ©e dans `benchmark.py`.

Elle repose sur la commande suivante :

```bash
python3 npuzzle/generate_npuzzle.py -s 3 -ml 10 -n 3 puzzles
```

Cela produit 3 puzzles par niveau de difficultÃ© (1 Ã  10) de taille 3x3, stockÃ©s dans le dossier `puzzles/`.

### 2. Lancer le benchmark

```bash
python3 benchmark.py
```

RÃ©sultats enregistrÃ©s dans `results/benchmark.csv`

### 3. Tracer la courbe

```bash
python3 plot_results.py
```

Une image `results/benchmark_plot.png` est gÃ©nÃ©rÃ©e dans le terminal. Elle n'est **pas affichÃ©e automatiquement** (car la VM n'a pas d'interface graphique).

---

## âš™ï¸ DÃ©tails techniques

### âœ”ï¸ BFS / DFS

ImplÃ©mentÃ©s manuellement avec une file (BFS) ou une pile (DFS).

### âœ”ï¸ A\*

Utilise une heuristique de **distance de Manhattan** sur chaque tuile.

### âœ”ï¸ Fichier `benchmark.csv`

Contient pour chaque puzzle :

* la difficultÃ© (`length`)
* lâ€™algorithme (`algo`)
* le temps de rÃ©solution (`time` en secondes)

---

## ğŸ“Š RÃ©sultats observÃ©s

* **A\*** est systÃ©matiquement le plus rapide et stable.
* **BFS** reste correct mais plus lent Ã  mesure que la difficultÃ© augmente.
* **DFS** est instable et inefficace : explore de trÃ¨s longs chemins.

Un graphe est gÃ©nÃ©rÃ© pour visualiser cette comparaison.

---

## ğŸ“Œ Remarques

* Tous les algorithmes fonctionnent sur des puzzles **rÃ©solubles uniquement** (filtrage automatique).
* Le code est compatible avec la **VM PATIA (Python 3.7.3)**.
* Le dÃ©pÃ´t est structurÃ© proprement pour permettre des rendus TP sÃ©parÃ©s.